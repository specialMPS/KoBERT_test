{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"5WHzQ5MCjuhW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1666714326841,"user_tz":-540,"elapsed":36464,"user":{"displayName":"MPS special","userId":"14769746348235507214"}},"outputId":"faa1f493-cc95-4174-ce65-b7e982b18a45"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting mxnet\n","  Downloading mxnet-1.9.1-py3-none-manylinux2014_x86_64.whl (49.1 MB)\n","\u001b[K     |████████████████████████████████| 49.1 MB 1.2 MB/s \n","\u001b[?25hRequirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.7/dist-packages (from mxnet) (1.21.6)\n","Collecting graphviz<0.9.0,>=0.8.1\n","  Downloading graphviz-0.8.4-py2.py3-none-any.whl (16 kB)\n","Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from mxnet) (2.23.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (2022.9.24)\n","Installing collected packages: graphviz, mxnet\n","  Attempting uninstall: graphviz\n","    Found existing installation: graphviz 0.10.1\n","    Uninstalling graphviz-0.10.1:\n","      Successfully uninstalled graphviz-0.10.1\n","Successfully installed graphviz-0.8.4 mxnet-1.9.1\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting gluonnlp\n","  Downloading gluonnlp-0.10.0.tar.gz (344 kB)\n","\u001b[K     |████████████████████████████████| 344 kB 25.0 MB/s \n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.3.5)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.64.1)\n","Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (1.21.6)\n","Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (0.29.32)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (21.3)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2022.4)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->gluonnlp) (3.0.9)\n","Building wheels for collected packages: gluonnlp\n","  Building wheel for gluonnlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gluonnlp: filename=gluonnlp-0.10.0-cp37-cp37m-linux_x86_64.whl size=595734 sha256=47e81b4c4c2f08b9dc4112b459de550e9844a3a5af5a4ad393eedc536c920462\n","  Stored in directory: /root/.cache/pip/wheels/be/b4/06/7f3fdfaf707e6b5e98b79c041e023acffbe395d78a527eae00\n","Successfully built gluonnlp\n","Installing collected packages: gluonnlp\n","Successfully installed gluonnlp-0.10.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[K     |████████████████████████████████| 1.3 MB 33.7 MB/s \n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.97\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.23.1-py3-none-any.whl (5.3 MB)\n","\u001b[K     |████████████████████████████████| 5.3 MB 16.4 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n","\u001b[K     |████████████████████████████████| 7.6 MB 42.3 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.13.0)\n","Collecting huggingface-hub<1.0,>=0.10.0\n","  Downloading huggingface_hub-0.10.1-py3-none-any.whl (163 kB)\n","\u001b[K     |████████████████████████████████| 163 kB 79.4 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.9.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.10.1 tokenizers-0.13.1 transformers-4.23.1\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.12.1+cu113)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (4.1.1)\n"]}],"source":["!pip install mxnet\n","!pip install gluonnlp pandas tqdm\n","!pip install sentencepiece\n","!pip install transformers\n","!pip install torch"]},{"cell_type":"code","source":["!pip install git+https://git@github.com/SKTBrain/KoBERT.git@master"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5hiCoaNPneB6","executionInfo":{"status":"ok","timestamp":1666714462124,"user_tz":-540,"elapsed":109398,"user":{"displayName":"MPS special","userId":"14769746348235507214"}},"outputId":"178b3fef-ff14-4a5d-da9e-fc794631ea13"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting git+https://****@github.com/SKTBrain/KoBERT.git@master\n","  Cloning https://****@github.com/SKTBrain/KoBERT.git (to revision master) to /tmp/pip-req-build-h4njnp93\n","  Running command git clone -q 'https://****@github.com/SKTBrain/KoBERT.git' /tmp/pip-req-build-h4njnp93\n","Collecting boto3<=1.15.18\n","  Downloading boto3-1.15.18-py2.py3-none-any.whl (129 kB)\n","\u001b[K     |████████████████████████████████| 129 kB 31.7 MB/s \n","\u001b[?25hRequirement already satisfied: gluonnlp<=0.10.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from kobert==0.2.3) (0.10.0)\n","Collecting mxnet<=1.7.0.post2,>=1.4.0\n","  Downloading mxnet-1.7.0.post2-py2.py3-none-manylinux2014_x86_64.whl (54.7 MB)\n","\u001b[K     |████████████████████████████████| 54.7 MB 37 kB/s \n","\u001b[?25hCollecting onnxruntime<=1.8.0,==1.8.0\n","  Downloading onnxruntime-1.8.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n","\u001b[K     |████████████████████████████████| 4.5 MB 70.0 MB/s \n","\u001b[?25hCollecting sentencepiece<=0.1.96,>=0.1.6\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 78.0 MB/s \n","\u001b[?25hCollecting torch<=1.10.1,>=1.7.0\n","  Downloading torch-1.10.1-cp37-cp37m-manylinux1_x86_64.whl (881.9 MB)\n","\u001b[K     |██████████████████████████████▎ | 834.1 MB 80.7 MB/s eta 0:00:01tcmalloc: large alloc 1147494400 bytes == 0x3a194000 @  0x7fb61d497615 0x58ead6 0x4f355e 0x4d222f 0x51041f 0x5b4ee6 0x58ff2e 0x510325 0x5b4ee6 0x58ff2e 0x50d482 0x4d00fb 0x50cb8d 0x4d00fb 0x50cb8d 0x4d00fb 0x50cb8d 0x4bac0a 0x538a76 0x590ae5 0x510280 0x5b4ee6 0x58ff2e 0x50d482 0x5b4ee6 0x58ff2e 0x50c4fc 0x58fd37 0x50ca37 0x5b4ee6 0x58ff2e\n","\u001b[K     |████████████████████████████████| 881.9 MB 16 kB/s \n","\u001b[?25hCollecting transformers<=4.8.1,>=4.8.1\n","  Downloading transformers-4.8.1-py3-none-any.whl (2.5 MB)\n","\u001b[K     |████████████████████████████████| 2.5 MB 59.9 MB/s \n","\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from onnxruntime<=1.8.0,==1.8.0->kobert==0.2.3) (3.17.3)\n","Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.7/dist-packages (from onnxruntime<=1.8.0,==1.8.0->kobert==0.2.3) (1.21.6)\n","Requirement already satisfied: flatbuffers in /usr/local/lib/python3.7/dist-packages (from onnxruntime<=1.8.0,==1.8.0->kobert==0.2.3) (1.12)\n","Collecting jmespath<1.0.0,>=0.7.1\n","  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n","Collecting s3transfer<0.4.0,>=0.3.0\n","  Downloading s3transfer-0.3.7-py2.py3-none-any.whl (73 kB)\n","\u001b[K     |████████████████████████████████| 73 kB 2.3 MB/s \n","\u001b[?25hCollecting botocore<1.19.0,>=1.18.18\n","  Downloading botocore-1.18.18-py2.py3-none-any.whl (6.7 MB)\n","\u001b[K     |████████████████████████████████| 6.7 MB 79.4 MB/s \n","\u001b[?25hRequirement already satisfied: urllib3<1.26,>=1.20 in /usr/local/lib/python3.7/dist-packages (from botocore<1.19.0,>=1.18.18->boto3<=1.15.18->kobert==0.2.3) (1.24.3)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.19.0,>=1.18.18->boto3<=1.15.18->kobert==0.2.3) (2.8.2)\n","Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from gluonnlp<=0.10.0,>=0.6.0->kobert==0.2.3) (0.29.32)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from gluonnlp<=0.10.0,>=0.6.0->kobert==0.2.3) (21.3)\n","Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from mxnet<=1.7.0.post2,>=1.4.0->kobert==0.2.3) (2.23.0)\n","Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from mxnet<=1.7.0.post2,>=1.4.0->kobert==0.2.3) (0.8.4)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.19.0,>=1.18.18->boto3<=1.15.18->kobert==0.2.3) (1.15.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet<=1.7.0.post2,>=1.4.0->kobert==0.2.3) (2022.9.24)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet<=1.7.0.post2,>=1.4.0->kobert==0.2.3) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet<=1.7.0.post2,>=1.4.0->kobert==0.2.3) (2.10)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<=1.10.1,>=1.7.0->kobert==0.2.3) (4.1.1)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (6.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (3.8.0)\n","Collecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 63.3 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (4.13.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (4.64.1)\n","Collecting huggingface-hub==0.0.12\n","  Downloading huggingface_hub-0.0.12-py3-none-any.whl (37 kB)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n","\u001b[K     |████████████████████████████████| 880 kB 89.6 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (2022.6.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->gluonnlp<=0.10.0,>=0.6.0->kobert==0.2.3) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (3.9.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (1.2.0)\n","Building wheels for collected packages: kobert, sacremoses\n","  Building wheel for kobert (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for kobert: filename=kobert-0.2.3-py3-none-any.whl size=15708 sha256=0e0d5c7e552ee061f8f165ec28bacedf57f793e8bb315222b54e1edbf27b379c\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-mv5v1upl/wheels/d3/68/ca/334747dfb038313b49cf71f84832a33372f3470d9ddfd051c0\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=c7714defa8095ce4dd79368d4611ac16422581efcbef46b8c380941b0fa07925\n","  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n","Successfully built kobert sacremoses\n","Installing collected packages: jmespath, botocore, tokenizers, sacremoses, s3transfer, huggingface-hub, transformers, torch, sentencepiece, onnxruntime, mxnet, boto3, kobert\n","  Attempting uninstall: tokenizers\n","    Found existing installation: tokenizers 0.13.1\n","    Uninstalling tokenizers-0.13.1:\n","      Successfully uninstalled tokenizers-0.13.1\n","  Attempting uninstall: huggingface-hub\n","    Found existing installation: huggingface-hub 0.10.1\n","    Uninstalling huggingface-hub-0.10.1:\n","      Successfully uninstalled huggingface-hub-0.10.1\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 4.23.1\n","    Uninstalling transformers-4.23.1:\n","      Successfully uninstalled transformers-4.23.1\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.12.1+cu113\n","    Uninstalling torch-1.12.1+cu113:\n","      Successfully uninstalled torch-1.12.1+cu113\n","  Attempting uninstall: sentencepiece\n","    Found existing installation: sentencepiece 0.1.97\n","    Uninstalling sentencepiece-0.1.97:\n","      Successfully uninstalled sentencepiece-0.1.97\n","  Attempting uninstall: mxnet\n","    Found existing installation: mxnet 1.9.1\n","    Uninstalling mxnet-1.9.1:\n","      Successfully uninstalled mxnet-1.9.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchvision 0.13.1+cu113 requires torch==1.12.1, but you have torch 1.10.1 which is incompatible.\n","torchtext 0.13.1 requires torch==1.12.1, but you have torch 1.10.1 which is incompatible.\n","torchaudio 0.12.1+cu113 requires torch==1.12.1, but you have torch 1.10.1 which is incompatible.\u001b[0m\n","Successfully installed boto3-1.15.18 botocore-1.18.18 huggingface-hub-0.0.12 jmespath-0.10.0 kobert-0.2.3 mxnet-1.7.0.post2 onnxruntime-1.8.0 s3transfer-0.3.7 sacremoses-0.0.53 sentencepiece-0.1.96 tokenizers-0.10.3 torch-1.10.1 transformers-4.8.1\n"]}]},{"cell_type":"code","source":["!pip install torch==1.9.0+cu111 torchvision==0.10.0+cu111 torchaudio==0.9.0 -f https://download.pytorch.org/whl/torch_stable.html"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":955},"id":"NYQGuVmS39SB","executionInfo":{"status":"ok","timestamp":1666713749932,"user_tz":-540,"elapsed":105521,"user":{"displayName":"MPS special","userId":"14769746348235507214"}},"outputId":"9ef7e74f-83e6-4315-89a3-db14703bb56b"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Looking in links: https://download.pytorch.org/whl/torch_stable.html\n","Collecting torch==1.9.0+cu111\n","  Downloading https://download.pytorch.org/whl/cu111/torch-1.9.0%2Bcu111-cp37-cp37m-linux_x86_64.whl (2041.3 MB)\n","\u001b[K     |█████████████                   | 834.1 MB 1.2 MB/s eta 0:16:32tcmalloc: large alloc 1147494400 bytes == 0x3ab68000 @  0x7f418ce9c615 0x58ead6 0x4f355e 0x4d222f 0x51041f 0x5b4ee6 0x58ff2e 0x510325 0x5b4ee6 0x58ff2e 0x50d482 0x4d00fb 0x50cb8d 0x4d00fb 0x50cb8d 0x4d00fb 0x50cb8d 0x4bac0a 0x538a76 0x590ae5 0x510280 0x5b4ee6 0x58ff2e 0x50d482 0x5b4ee6 0x58ff2e 0x50c4fc 0x58fd37 0x50ca37 0x5b4ee6 0x58ff2e\n","\u001b[K     |████████████████▌               | 1055.7 MB 113.4 MB/s eta 0:00:09tcmalloc: large alloc 1434370048 bytes == 0x7f1be000 @  0x7f418ce9c615 0x58ead6 0x4f355e 0x4d222f 0x51041f 0x5b4ee6 0x58ff2e 0x510325 0x5b4ee6 0x58ff2e 0x50d482 0x4d00fb 0x50cb8d 0x4d00fb 0x50cb8d 0x4d00fb 0x50cb8d 0x4bac0a 0x538a76 0x590ae5 0x510280 0x5b4ee6 0x58ff2e 0x50d482 0x5b4ee6 0x58ff2e 0x50c4fc 0x58fd37 0x50ca37 0x5b4ee6 0x58ff2e\n","\u001b[K     |█████████████████████           | 1336.2 MB 1.2 MB/s eta 0:10:01tcmalloc: large alloc 1792966656 bytes == 0x3ff0000 @  0x7f418ce9c615 0x58ead6 0x4f355e 0x4d222f 0x51041f 0x5b4ee6 0x58ff2e 0x510325 0x5b4ee6 0x58ff2e 0x50d482 0x4d00fb 0x50cb8d 0x4d00fb 0x50cb8d 0x4d00fb 0x50cb8d 0x4bac0a 0x538a76 0x590ae5 0x510280 0x5b4ee6 0x58ff2e 0x50d482 0x5b4ee6 0x58ff2e 0x50c4fc 0x58fd37 0x50ca37 0x5b4ee6 0x58ff2e\n","\u001b[K     |██████████████████████████      | 1652.1 MB 1.2 MB/s eta 0:05:27"]},{"output_type":"stream","name":"stderr","text":["IOPub data rate exceeded.\n","The notebook server will temporarily stop sending output\n","to the client in order to avoid crashing it.\n","To change this limit, set the config variable\n","`--NotebookApp.iopub_data_rate_limit`.\n","\n","Current values:\n","NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n","NotebookApp.rate_limit_window=3.0 (secs)\n","\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[K     |████████████████████████████████| 2041.3 MB 1.1 MB/s eta 0:00:01tcmalloc: large alloc 2041348096 bytes == 0xf473a000 @  0x7f418ce9b1e7 0x4b2590 0x4b261c 0x58ead6 0x4f355e 0x4d222f 0x51041f 0x5b4ee6 0x58ff2e 0x50ca37 0x5b4ee6 0x58ff2e 0x50ca37 0x5b4ee6 0x58ff2e 0x50ca37 0x5b4ee6 0x58ff2e 0x50ca37 0x5b4ee6 0x58ff2e 0x50ca37 0x58fd37 0x50ca37 0x5b4ee6 0x58ff2e 0x50d482 0x5b4ee6 0x58ff2e 0x50d482 0x5b4ee6\n","tcmalloc: large alloc 2551685120 bytes == 0x1e26a8000 @  0x7f418ce9c615 0x58ead6 0x4f355e 0x4d222f 0x51041f 0x5b4ee6 0x58ff2e 0x50ca37 0x5b4ee6 0x58ff2e 0x50ca37 0x5b4ee6 0x58ff2e 0x50ca37 0x5b4ee6 0x58ff2e 0x50ca37 0x5b4ee6 0x58ff2e 0x50ca37 0x58fd37 0x50ca37 0x5b4ee6 0x58ff2e 0x50d482 0x5b4ee6 0x58ff2e 0x50d482 0x5b4ee6 0x4bad99 0x4d3249\n","\u001b[K     |████████████████████████████████| 2041.3 MB 7.5 kB/s \n","\u001b[?25hCollecting torchvision==0.10.0+cu111\n","  Downloading https://download.pytorch.org/whl/cu111/torchvision-0.10.0%2Bcu111-cp37-cp37m-linux_x86_64.whl (23.2 MB)\n","\u001b[K     |████████████████████████████████| 23.2 MB 89.5 MB/s \n","\u001b[?25hCollecting torchaudio==0.9.0\n","  Downloading torchaudio-0.9.0-cp37-cp37m-manylinux1_x86_64.whl (1.9 MB)\n","\u001b[K     |████████████████████████████████| 1.9 MB 4.7 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0+cu111) (4.1.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==0.10.0+cu111) (1.21.6)\n","Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.10.0+cu111) (7.1.2)\n","Installing collected packages: torch, torchvision, torchaudio\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.10.1\n","    Uninstalling torch-1.10.1:\n","      Successfully uninstalled torch-1.10.1\n","  Attempting uninstall: torchvision\n","    Found existing installation: torchvision 0.13.1+cu113\n","    Uninstalling torchvision-0.13.1+cu113:\n","      Successfully uninstalled torchvision-0.13.1+cu113\n","  Attempting uninstall: torchaudio\n","    Found existing installation: torchaudio 0.12.1+cu113\n","    Uninstalling torchaudio-0.12.1+cu113:\n","      Successfully uninstalled torchaudio-0.12.1+cu113\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchtext 0.13.1 requires torch==1.12.1, but you have torch 1.9.0+cu111 which is incompatible.\u001b[0m\n","Successfully installed torch-1.9.0+cu111 torchaudio-0.9.0 torchvision-0.10.0+cu111\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["torch"]}}},"metadata":{}}]},{"cell_type":"code","source":["import torch\n","from torch import nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","import gluonnlp as nlp\n","import numpy as np\n","from tqdm import tqdm, tqdm_notebook\n","import pandas as pd\n","\n","from transformers import AdamW\n","from transformers.optimization import get_cosine_schedule_with_warmup\n","from transformers import BertModel\n","\n","from gluonnlp.data import SentencepieceTokenizer\n","from kobert.utils import get_tokenizer\n","from kobert.pytorch_kobert import get_pytorch_kobert_model\n","\n","# GPU\n","device = torch.device(\"cuda:0\")"],"metadata":{"id":"MjlB0bXWpXUL","executionInfo":{"status":"ok","timestamp":1666714467673,"user_tz":-540,"elapsed":5555,"user":{"displayName":"MPS special","userId":"14769746348235507214"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["import gc\n","\n","gc.collect()\n","torch.cuda.empty_cache()"],"metadata":{"id":"uimG_P055uUc","executionInfo":{"status":"ok","timestamp":1666714467674,"user_tz":-540,"elapsed":15,"user":{"displayName":"MPS special","userId":"14769746348235507214"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["bertmodel, vocab = get_pytorch_kobert_model()\n","\n","tokenizer = get_tokenizer()\n","tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tEix92usnntf","executionInfo":{"status":"ok","timestamp":1666714478381,"user_tz":-540,"elapsed":10721,"user":{"displayName":"MPS special","userId":"14769746348235507214"}},"outputId":"8a47135d-a6ae-4031-f4c1-1ee07503d8d6"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/.cache/kobert_v1.zip[██████████████████████████████████████████████████]\n","/content/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece[██████████████████████████████████████████████████]\n","using cached model. /content/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"]}]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19785,"status":"ok","timestamp":1666714498156,"user":{"displayName":"MPS special","userId":"14769746348235507214"},"user_tz":-540},"id":"67OCuTUVp9DO","outputId":"e93dce0b-677e-4ee2-a0c7-48fefcf20a56"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /gdrive\n"]}],"source":["# google drive mount\n","\n","from google.colab import drive\n","drive.mount('/gdrive', force_remount=True)"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1666714498156,"user":{"displayName":"MPS special","userId":"14769746348235507214"},"user_tz":-540},"id":"mCn5Z3LHqUX9","outputId":"ed50a1e3-4297-4eed-973b-440a3910cb9c"},"outputs":[{"output_type":"stream","name":"stdout","text":["/gdrive/My Drive/KoBERT\n"]}],"source":["# directory path\n","\n","%cd '/gdrive/My Drive/KoBERT/'"]},{"cell_type":"code","source":["# data loading\n","\n","import pandas as pd\n","\n","dataset = pd.read_csv('/gdrive/My Drive/KoBERT/data/data_2.csv')\n","dataset.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"eACemgj88zD0","executionInfo":{"status":"ok","timestamp":1666714500006,"user_tz":-540,"elapsed":1855,"user":{"displayName":"MPS special","userId":"14769746348235507214"}},"outputId":"3d510d5f-7eec-4050-a452-d9b8ea5c4648"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                        sentence emotion\n","0  제 감정이 이상해진 것 같아요 남편만 보면 화가 치밀어 오르고 감정 조절이 안돼요      화남\n","1                         더 이상 내 감정을 내가 컨트롤 못하겠어     비참함\n","2                    하루 종일 오르락내리락 롤러코스터 타는 기분이에요     비참함\n","3                               꼭 롤러코스터 타는 것 같아요     긴장됨\n","4                      롤러코스터 타는 것처럼 기분이 왔다 갔다 해요     우울함"],"text/html":["\n","  <div id=\"df-e63415e1-70c3-41fc-875c-67bc797974b3\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentence</th>\n","      <th>emotion</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>제 감정이 이상해진 것 같아요 남편만 보면 화가 치밀어 오르고 감정 조절이 안돼요</td>\n","      <td>화남</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>더 이상 내 감정을 내가 컨트롤 못하겠어</td>\n","      <td>비참함</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>하루 종일 오르락내리락 롤러코스터 타는 기분이에요</td>\n","      <td>비참함</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>꼭 롤러코스터 타는 것 같아요</td>\n","      <td>긴장됨</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>롤러코스터 타는 것처럼 기분이 왔다 갔다 해요</td>\n","      <td>우울함</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e63415e1-70c3-41fc-875c-67bc797974b3')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-e63415e1-70c3-41fc-875c-67bc797974b3 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-e63415e1-70c3-41fc-875c-67bc797974b3');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["# emotion labeling\n","\n","emotion_labels = {'중립': 0,\n","                  '기쁨': 1,\n","                  '놀람': 2,\n","                  '긴장됨': 3,\n","                  '괴로움': 4,\n","                  '화남': 5,\n","                  '비참함': 6,\n","                  '우울함': 7,\n","                  '피로함': 8}\n","\n","data_list = []\n","for q, label in zip(dataset['sentence'], dataset['emotion']):\n","  data = []\n","  data.append(q)\n","  data.append(str(emotion_labels[label]))\n","\n","  data_list.append(data)"],"metadata":{"id":"pMkBNHkSqUEK","executionInfo":{"status":"ok","timestamp":1666714500009,"user_tz":-540,"elapsed":16,"user":{"displayName":"MPS special","userId":"14769746348235507214"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1666714500010,"user":{"displayName":"MPS special","userId":"14769746348235507214"},"user_tz":-540},"id":"zRCzqETNCJUd"},"outputs":[],"source":["# tokenizing\n","\n","class EmotionDataset(Dataset):\n","  def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, vocab, max_len, pad, pair):\n","    transform = nlp.data.BERTSentenceTransform(bert_tokenizer, \n","                                               max_seq_length=max_len, vocab=vocab, pad=pad, pair=pair) \n","\n","    self.sentences = [transform([i[sent_idx]]) for i in dataset]\n","    self.labels = [np.int32(i[label_idx]) for i in dataset]\n","\n","  def __getitem__(self, i):\n","    return (self.sentences[i] + (self.labels[i], ))\n","\n","  def __len__(self):\n","    return (len(self.labels))"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"vMgLbTlUCjWi","executionInfo":{"status":"ok","timestamp":1666714500012,"user_tz":-540,"elapsed":14,"user":{"displayName":"MPS special","userId":"14769746348235507214"}}},"outputs":[],"source":["# parameters\n","\n","max_len = 256\n","batch_size = 32\n","warmup_ratio = 0.1\n","num_epochs = 10\n","max_grad_norm = 1\n","log_interval = 200\n","learning_rate =  5e-5"]},{"cell_type":"code","source":["# train/test 분리\n","\n","from sklearn.model_selection import train_test_split\n","\n","train, test = train_test_split(data_list, test_size=0.2, shuffle=True, random_state=42)\n","print(\"train:\", len(train))\n","print(\"test:\", len(test))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E5lr75ARtWrC","executionInfo":{"status":"ok","timestamp":1666714500477,"user_tz":-540,"elapsed":479,"user":{"displayName":"MPS special","userId":"14769746348235507214"}},"outputId":"fc8ff70f-180d-4392-dd12-dd198c9aef7e"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["train: 38992\n","test: 9748\n"]}]},{"cell_type":"code","source":["# train/test data tokenizing\n","\n","data_train = EmotionDataset(train, 0, 1, tok, vocab, max_len, True, False)\n","data_test = EmotionDataset(test, 0, 1, tok, vocab, max_len, True, False)"],"metadata":{"id":"B8WsNGZ6t6GW","executionInfo":{"status":"ok","timestamp":1666714504909,"user_tz":-540,"elapsed":4435,"user":{"displayName":"MPS special","userId":"14769746348235507214"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["# make torch type dataset\n","\n","train_dataloader = torch.utils.data.DataLoader(data_train, batch_size=batch_size, num_workers=5)\n","test_dataloader = torch.utils.data.DataLoader(data_test, batch_size=batch_size, num_workers=5)"],"metadata":{"id":"bV5AeJVyvejq","executionInfo":{"status":"ok","timestamp":1666714504915,"user_tz":-540,"elapsed":44,"user":{"displayName":"MPS special","userId":"14769746348235507214"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"83d3bd68-c82f-44cc-c48e-3ab4520833ab"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]}]},{"cell_type":"code","execution_count":15,"metadata":{"id":"XNY9TmyWpnd9","executionInfo":{"status":"ok","timestamp":1666714504916,"user_tz":-540,"elapsed":32,"user":{"displayName":"MPS special","userId":"14769746348235507214"}}},"outputs":[],"source":["# classifier\n","\n","class EmotionClassifier(nn.Module):\n","  def __init__(self,\n","               bert,\n","               hidden_size = 768,\n","               num_classes = 9,\n","               dr_rate = None,\n","               params = None):\n","    super(EmotionClassifier, self).__init__()\n","    self.bert = bert\n","    self.dr_rate = dr_rate\n","\n","    self.classifier = nn.Linear(hidden_size, num_classes)\n","    if dr_rate:\n","      self.dropout = nn.Dropout(p=dr_rate)\n","\n","  def gen_attention_mask(self, token_ids, valid_length):\n","    attention_mask = torch.zeros_like(token_ids)\n","    for i, v in enumerate(valid_length):\n","      attention_mask[i][:v] = 1\n","    return attention_mask.float()\n","\n","  def forward(self, token_ids, valid_length, segment_ids):\n","    attention_mask = self.gen_attention_mask(token_ids, valid_length)\n","    \n","    _, pooler = self.bert(input_ids=token_ids, token_type_ids=segment_ids.long(), \n","                          attention_mask=attention_mask.float().to(token_ids.device), return_dict=False)\n","    \n","    if self.dr_rate:\n","      out = self.dropout(pooler)\n","    \n","    return self.classifier(out)"]},{"cell_type":"code","source":["model = EmotionClassifier(bertmodel, dr_rate=0.5).to(device)\n","\n","# optimizer and schedule\n","no_decay = ['bias', 'LayerNorm.weight']\n","optimizer_grouped_parameters = [\n","    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n","    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}]\n","\n","optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate)\n","loss_fn = nn.CrossEntropyLoss()\n","\n","t_total = len(train_dataloader) * num_epochs\n","warmup_step = int(t_total * warmup_ratio)\n","\n","scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=warmup_step, num_training_steps=t_total)\n","\n","# accuracy calculate\n","def calc_accuracy(X, y):\n","  max_vals, max_indices = torch.max(X, 1)\n","  train_acc = (max_indices == y).sum().data.cpu().numpy()/max_indices.size()[0]\n","  return train_acc"],"metadata":{"id":"N6nvmCA5v7hy","executionInfo":{"status":"ok","timestamp":1666714508464,"user_tz":-540,"elapsed":3579,"user":{"displayName":"MPS special","userId":"14769746348235507214"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["# train\n","\n","train_list = []\n","test_list = []\n","loss_list = []\n","\n","for e in range(num_epochs):\n","  train_acc = 0.0\n","  test_acc = 0.0\n","    \n","  model.train()\n","\n","  for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(train_dataloader)):\n","    optimizer.zero_grad()\n","    token_ids = token_ids.long().to(device)\n","    segment_ids = segment_ids.long().to(device)\n","    valid_length = valid_length\n","    label = label.long().to(device)\n","    out = model(token_ids, valid_length, segment_ids)\n","\n","    loss = loss_fn(out, label)\n","    loss.backward()\n","    torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n","    optimizer.step()\n","    scheduler.step()\n","    train_acc += calc_accuracy(out, label)\n","    if batch_id % log_interval == 0:\n","      print(\"epoch {} batch id {} loss {} train acc {}\".format(e+1, batch_id+1, loss.data.cpu().numpy(), train_acc / (batch_id+1)))\n","      train_list.append(train_acc / (batch_id+1))\n","      loss_list.append(loss.data.cpu().numpy())\n","    \n","  print(\"epoch {} train acc {}\".format(e+1, train_acc / (batch_id+1)))\n","  \n","  model.eval() # 평가 모드로 변경\n","  \n","  for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(test_dataloader)):\n","    token_ids = token_ids.long().to(device)\n","    segment_ids = segment_ids.long().to(device)\n","    valid_length = valid_length\n","    label = label.long().to(device)\n","    out = model(token_ids, valid_length, segment_ids)\n","    test_acc += calc_accuracy(out, label)\n","\n","  print(\"epoch {} test acc {}\".format(e+1, test_acc / (batch_id+1)))\n","  test_list.append(test_acc / (batch_id+1))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":179,"referenced_widgets":["bd4cfea96ae9435782b96ca3d68a78d2","1e9821f809124b81a754e664c9231403","00d93a95b21c4fe583d35e51a1f91ea8","a04c2975b1324ffa90af98ca98ed6f51","0863487d55ef4de69eaaa5670137a07c","d46122ca67c648029e283ee773c4ba65","3865df224c434da0b6c845d82592afd6","8744443b9d064a9d9773f215f0c2a8c9","fbc485b6da044edd9771c602a2ae521b","02cb3e7a05014fa88568389b662e0717","adcb4b5bdf9e45bbafde3dbdd4a07f1b"]},"id":"AvcKEEj4xBSA","outputId":"27cec78e-823e-4fb1-9f90-3d8028c4e1c5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n","Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n","  del sys.path[0]\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/1219 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bd4cfea96ae9435782b96ca3d68a78d2"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["epoch 1 batch id 1 loss 2.275239944458008 train acc 0.0625\n","epoch 1 batch id 201 loss 2.0467629432678223 train acc 0.1433457711442786\n","epoch 1 batch id 401 loss 1.7492173910140991 train acc 0.19334476309226933\n"]}]},{"cell_type":"code","source":["# save model\n","\n","checkpoint_path = '/gdrive/My Drive/KoBERT/checkpoint/'\n","torch.save(model, checkpoint_path + 'kobert.pth')\n"],"metadata":{"id":"YrSsCVUq47mk"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cX2oVFqhQZDj","outputId":"dbef3878-72fe-49f3-c9dc-d7f5f5976ff3","executionInfo":{"status":"ok","timestamp":1665925153314,"user_tz":-540,"elapsed":32117,"user":{"displayName":"MPS special","userId":"14769746348235507214"}}},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Sentence: 친구는 놀러갔는데 나는 일만 해\n","Emotion: 화남, softmax_value: 0.17196279764175415\n","--------------------------------------------------\n","\n","Sentence: 옆자리 사람이 자꾸 뭐라 해\n","Emotion: 화남, softmax_value: 0.17196279764175415\n","--------------------------------------------------\n","\n","Sentence: 엥\n","Emotion: 화남, softmax_value: 0.17196279764175415\n","--------------------------------------------------\n","\n","Sentence: 종료\n"]}],"source":["# test\n","\n","import random\n","\n","def kobert_input(tokenizer, str, device=None, max_seq_len=256):\n","    index_of_words = tokenizer.encode(str)\n","    token_type_ids = [0] * len(index_of_words)\n","    attention_mask = [1] * len(index_of_words)\n","\n","    # Padding Length\n","    padding_length = max_seq_len - len(index_of_words)\n","\n","    # Zero Padding\n","    index_of_words += [0] * padding_length\n","    token_type_ids += [0] * padding_length\n","    attention_mask += [0] * padding_length\n","\n","    data = {\n","        'input_ids': torch.tensor([index_of_words]).to(device),\n","        'token_type_ids': torch.tensor([token_type_ids]).to(device),\n","        'attention_mask': torch.tensor([attention_mask]).to(device),\n","    }\n","    return data\n","\n","\n","if __name__ == \"__main__\":\n","    checkpoint_path = \"/gdrive/My Drive/KoBERT/checkpoint\"\n","    save_ckpt_path = f\"{checkpoint_path}/kobert.pth\"\n","\n","    emotion_labels = {'중립': 0,\n","                      '기쁨': 1,\n","                      '놀람': 2,\n","                      '긴장됨': 3,\n","                      '괴로움': 4,\n","                      '화남': 5,\n","                      '비참함': 6,\n","                      '우울함': 7,\n","                      '피로함': 8}\n","    flip_emotion_labels = {v: k for k, v in emotion_labels.items()}\n","\n","    ctx = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","    device = torch.device(ctx)\n","\n","    # 저장한 Checkpoint 불러오기\n","    checkpoint = torch.load(save_ckpt_path, map_location=device)\n","\n","    model = EmotionClassifier()\n","    model.load_state_dict(checkpoint['model_state_dict'])\n","\n","    model.to(ctx)\n","    model.eval()\n","\n","    tokenizer = get_tokenizer()\n","\n","    while 1:\n","        sent = input('\\nSentence: ')  # '요즘 기분이 우울한 느낌이에요'\n","        data = kobert_input(tokenizer, sent, device, 512)\n","\n","\n","        if '종료' in sent:\n","            break\n","\n","        output = model(**data)\n","\n","        logit = output[0]\n","        softmax_logit = torch.softmax(logit, dim=-1)\n","        softmax_logit = softmax_logit.squeeze()\n","\n","        max_index = torch.argmax(softmax_logit).item()\n","        max_index_value = softmax_logit[torch.argmax(softmax_logit)].item()\n","\n","        emotion = flip_emotion_labels[max_index]\n","\n","        print(f'Emotion: {emotion}, softmax_value: {max_index_value}')\n","        print('-' * 50)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-mPqNXo-kQAJ"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","provenance":[{"file_id":"1WMQTRgIn7HBZ1Tp2vOLMOZtuBN2-pO1E","timestamp":1666697884707}],"authorship_tag":"ABX9TyML/SGyTn5dGQZsUL+yD6c9"},"gpuClass":"premium","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"bd4cfea96ae9435782b96ca3d68a78d2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1e9821f809124b81a754e664c9231403","IPY_MODEL_00d93a95b21c4fe583d35e51a1f91ea8","IPY_MODEL_a04c2975b1324ffa90af98ca98ed6f51"],"layout":"IPY_MODEL_0863487d55ef4de69eaaa5670137a07c"}},"1e9821f809124b81a754e664c9231403":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d46122ca67c648029e283ee773c4ba65","placeholder":"​","style":"IPY_MODEL_3865df224c434da0b6c845d82592afd6","value":" 34%"}},"00d93a95b21c4fe583d35e51a1f91ea8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_8744443b9d064a9d9773f215f0c2a8c9","max":1219,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fbc485b6da044edd9771c602a2ae521b","value":415}},"a04c2975b1324ffa90af98ca98ed6f51":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_02cb3e7a05014fa88568389b662e0717","placeholder":"​","style":"IPY_MODEL_adcb4b5bdf9e45bbafde3dbdd4a07f1b","value":" 414/1219 [09:24&lt;18:48,  1.40s/it]"}},"0863487d55ef4de69eaaa5670137a07c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d46122ca67c648029e283ee773c4ba65":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3865df224c434da0b6c845d82592afd6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8744443b9d064a9d9773f215f0c2a8c9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fbc485b6da044edd9771c602a2ae521b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"02cb3e7a05014fa88568389b662e0717":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"adcb4b5bdf9e45bbafde3dbdd4a07f1b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}